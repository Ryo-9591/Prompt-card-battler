services:
  web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: web
    ports:
      - "3000:3000"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=gemma3:1b
    depends_on:
      - ollama
    restart: always
    deploy:
      resources:
        limits:
          memory: 6G
        reservations:
          memory: 4G

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ./ollama-data:/root/.ollama
    restart: always
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 6G
        # GPUを使用する場合は以下のコメントアウトを外してください (NVIDIA GPUが必要)
        # devices:
        #   - driver: nvidia
        #     count: 1
        #     capabilities: [gpu]

  ollama-pull:
    image: curlimages/curl:latest
    container_name: ollama-pull
    depends_on:
      - ollama
    restart: "no"
    command: >
      sh -c "sleep 10; curl http://ollama:11434/api/pull -d '{\"name\": \"gemma3:1b\"}'"
